{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellView": "form",
    "id": "ur8xi4C7S06n"
   },
   "outputs": [],
   "source": [
    "# @title Copyright & License (click to expand)\n",
    "# Copyright 2021 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fsv4jGuU89rX"
   },
   "source": [
    "# All Together Now\n",
    "\n",
    "In this notebook, we'll connect the pieces you've already built:\n",
    "\n",
    "* engineered features\n",
    "* feature store\n",
    "* model\n",
    "* endpoint\n",
    "\n",
    "into one web application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lA32H1oKGgpf"
   },
   "source": [
    "## App Description\n",
    "\n",
    "The application we're deploying consists of the following four microservices deployed to Google Cloud Run:\n",
    "\n",
    "* ff-web - the web user interface\n",
    "* ff-datagen - the data generator, produces a live stream of fabricated financial transactions\n",
    "* ff-predict - the predictor, reads a pub/sub queue of streaming transactions, combines incoming transaction data with corresponding aggregates from the feature store, makes model predictions, and deposits the results in a BigQuery table\n",
    "* ff-server - the Vertex server, this provides access to the Vertex AI API so your app can query and display the resources in your project\n",
    "\n",
    "Here's a block diagram of the application you will deploy:\n",
    "\n",
    "<img src=\"../assets/app_diagram.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t6Cd51FkG09E"
   },
   "source": [
    "### What is Cloud Run and why should I care?\n",
    "\n",
    "That sounds like a good excuse for a demo! Rather than tell you, let me show you! (live demo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8yVpQt-JHKPF"
   },
   "source": [
    "### Costs \n",
    "\n",
    "This tutorial uses billable components of Google Cloud:\n",
    "\n",
    "* Cloud Run\n",
    "* Pub/Sub\n",
    "* Vertex AI\n",
    "* BigQuery\n",
    "\n",
    "Learn about [Vertext AI\n",
    "pricing](https://cloud.google.com/vertex-ai/pricing) and [Cloud Storage\n",
    "pricing](https://cloud.google.com/storage/pricing), and use the [Pricing\n",
    "Calculator](https://cloud.google.com/products/calculator/)\n",
    "to generate a cost estimate based on your projected usage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tvgnzT1CKxrO"
   },
   "source": [
    "### View Your Cloud Run Services\n",
    "\n",
    "\n",
    "Navigate to the Cloud Run service and notice the four microservices are already deployed. That was done in the *init* script you in lab setup steps.\n",
    "\n",
    "<img src=\"../assets/cloud_run.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visit the Web App\n",
    "\n",
    "Drill into the *ff-web* service and click on the URL shown for accessing the service.\n",
    "\n",
    "<img src=\"../assets/ff-web.png\"/>\n",
    "\n",
    "You should then see this page:\n",
    "\n",
    "<img src=\"../assets/home_page.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the web app starts on the config tab. It needs to know several things about your environment so that it can find various resources, like the URLs for your associated microservices, the name of your feature store name, and your prediction endpoint.\n",
    "\n",
    "Fill in the following config data from the sources note below:\n",
    "\n",
    "* Server URLs ((datagen, predict, and server) - Navigate to the Cloud Run service pages for ff-datagen, ff-predict, and ff-server. Click on the icon that copies those service links to the clipboard and paste them into the corresponding input box on the fraudfinder app's Config tab.\n",
    "* Feature Store ID - Navigate to the Vertex AI -> Features page, copy the name for your feature store (should have the format fraudfinder_<number>), and paste it into the corresponding input box on the fraudfinder app's Config tab.\n",
    "* Endpoint ID - Navigate to the Vertex AI -> Endpoints page, copy the ID for your deployed endpoint, and paste it into the corresponding input box on the fraudfinder app's Config tab.\n",
    "    \n",
    "Your configuration settings are stored locally so there's no need to re-enter them in the future.\n",
    "    \n",
    "Now your app is fully configured and ready to go!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7EUnXsZhAGF"
   },
   "source": [
    "### Start the Data Generator\n",
    "\n",
    "Select the \"Datagen\" tab, which connects to the ff-datagen microservice. Verify the status is \"Connected\" (it may take a few seconds), and click the  \"Start Stream\" button. This will take roughly 10s to get started, after which you should begin to see transactions streaming into the embedded table. These transactions are placed on a Pub/Sub queue for consumption by the ff-predict service. Fraudulent transactions are highlight in yellow.\n",
    "\n",
    "<img src=\"../assets/datagen.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify the Predictor is Running\n",
    "\n",
    "Once the streaming has started, select the \"Predict\" tab, which connects to the ff-predict microservice. Verify the status is \"Connected\" and you should see prediction results streaming into the embedded table. The ff-predict microservice is repeatedly removing transactions from the Pub/Sub queue, reading features from the feature store corresponing the transaction's customer id and terminal id, making a prediction via your deployed model, and depositing the results in a BigQuery table. Transactions determined to be fraudulent by model predictions are highlighted in yellow.\n",
    "\n",
    "<img src=\"../assets/predict.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check out the Dashboard\n",
    "\n",
    "Once the predictions start arriving, select the \"Dashboard\" tab to see a graphical representation of the incoming data, updated in real time.\n",
    "\n",
    "<img src=\"../assets/dashboard.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify the results are stored in BigQuery\n",
    "\n",
    "Navigate to the BigQuery service page, select the tx dataset, then the *predictions* table, and verify that the streaming prediction results have been stored by selecting the preview tab. You now have all the power of BigQuery at your disposal to analyze your data.\n",
    "\n",
    "<img src=\"../assets/bq.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratulations - you've completed the Fraudfinder lab\n",
    "\n",
    "**You are now a certified Transaction Detective!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "model_monitoring_feature_attribs.ipynb",
   "toc_visible": true
  },
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m87",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m87"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
